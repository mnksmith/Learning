{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "\n",
    "### Decision Tree Classifier\n",
    "- Has max_depth as a hyperparameter.\n",
    "- Divides the feature space into rectangular regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0]\n",
      "Test set accuracy: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnksmith/anaconda/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py:4531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  limit=limit, regex=regex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "wbc = pd.read_csv('dc_wbc.csv')\n",
    "\n",
    "X = wbc[['radius_mean', 'concave points_mean']]\n",
    "y = wbc[['diagnosis']]\n",
    "y.replace({'M': 1, 'B': 0}, inplace=True)\n",
    "SEED = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=SEED)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1688ecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_test.loc[y_test['diagnosis']==1]['radius_mean'], X_test.loc[y_test['diagnosis']==1]['concave points_mean'], marker = '^', c='blue')\n",
    "plt.scatter(X_test.loc[y_test['diagnosis']==0]['radius_mean'], X_test.loc[y_test['diagnosis']==0]['concave points_mean'], marker = 's', c='red')\n",
    "\n",
    "plot_step = 0.001\n",
    "x_min, x_max = X_test['radius_mean'].min() - 1, X_test['radius_mean'].max() + 1\n",
    "y_min, y_max = X_test['concave points_mean'].min() - 0.01, X_test['concave points_mean'].max() + 0.01\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "Z = dt.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.3)\n",
    "plt.xlabel('radius mean')\n",
    "plt.ylabel('concave points mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification tree learning\n",
    "\n",
    "Nodes are grown recursively. A node exists depending on the state of its predecessors.\n",
    "\n",
    "At each node, split the data based on a feature and a split point criterion to maximize the information gained (can use entropy or gini index). The information gained depends on the \"impurity\" of each node involved.\n",
    "\n",
    "If no energy is gained, it's a leaf/prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.8947368421052632\n",
      "Accuracy achieved by using the gini index:  0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred_e = dt_entropy.predict(X_test)\n",
    "y_pred_g = dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred_e, y_test)\n",
    "accuracy_gini = accuracy_score(y_pred_g, y_test)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)\n",
    "\n",
    "# Print accuracy_gini\n",
    "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "\n",
    "For a regression tree, the impurity of a node is measured using the mean squared error of the targets in that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression test set RMSE: 3.82\n",
      "Regression Tree test set RMSE: 4.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "auto = pd.read_csv('dc_auto-mpg2.csv')\n",
    "\n",
    "X = auto.drop('mpg', axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "y = auto[['mpg']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=8,\n",
    "             min_samples_leaf=0.13,\n",
    "            random_state=3)\n",
    "lr = LinearRegression()\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "mse_lr = MSE(y_test, y_pred_lr)\n",
    "\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "rmse_lr = mse_lr**(1/2)\n",
    "\n",
    "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
    "print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias vs Variance\n",
    "\n",
    "Overfitting vs underfitting.\n",
    "\n",
    "Find the balance between bias and variance that minimizes the Generalization Error.\n",
    "\n",
    "High Variance:\n",
    "- CV error greater than the training set error\n",
    "- This mean's there's overfitting\n",
    "- Decrease model complexity or gather more data\n",
    "\n",
    "High Bias:\n",
    "- CV error is much higher than desired error\n",
    "- This means there's underfitting\n",
    "- Increase model complexity or gather more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n",
      "Train RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=1)\n",
    "\n",
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dt suffers from high bias, i.e., it's underfitting the data, because both errors are about the same, and too high.\n",
    "\n",
    "### Ensemble Learning\n",
    "\n",
    "Classification and Regression Trees (CARTs) are sensitive to small variations in the training set. They are vulnerable to high variance and may overfit, if unconstrained.\n",
    "\n",
    "In Ensemble Learning, we train different models on the same data, then aggregate the predictions with a meta-model so that the final prediction result is more robust.\n",
    "\n",
    "E.g. hard voting: each classifier used to train gets a \"vote\" and the final voting classifier predicts the result with the most votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.764\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "liver = pd.read_csv('dc_indian_liver_patient_preprocessed.csv', index_col=0)\n",
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver[['Liver_disease']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "SEED=1\n",
    "\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "knn = KNN(n_neighbors=27)\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    clf.fit(X_train, np.ravel(y_train))  \n",
    "   \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnksmith/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "vc.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Random Forests\n",
    "\n",
    "### Bootstrap aggregation, or Bagging\n",
    "\n",
    "In Bagging, you use one algorithm, but train on different subsets of the data (with replacement).  This reduces variance.\n",
    "\n",
    "In classification, the final prediction is given by majority voting.\n",
    "\n",
    "In regression, the final prediction is given by averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1)\n",
    "\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)\n",
    "\n",
    "bc.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Bag (OOB)\n",
    "\n",
    "Include the samples not selected by bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.718, OOB accuracy: 0.684\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)\n",
    "bc.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "Each estimator is trained on a different bootstrapped sample having the same size as the training set.\n",
    "\n",
    "A number of features *d* are sampled at each node (without replacement). The one that maximizes information gain is selected.\n",
    "\n",
    "Aggregates predictions by majority voting.\n",
    "\n",
    "In general, gets a lower variance than regular decision trees.\n",
    "\n",
    "Feature importance can be accessed by extracting the `feature_importance_` attribute of the classifier after fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 51.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "bikes = pd.read_csv('dc_bikes.csv')\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "y = bikes[['cnt']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=2)\n",
    "              \n",
    "rf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Features Importances')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a168bac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pd.Series(data=rf.feature_importances_, index= X_train.columns)\n",
    "\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='darkblue')\n",
    "plt.title('Features Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "Many weak learners are combined to form a strong learner. They are trained sequentially and each tries to correct the mistakes made by its predecessors.\n",
    "\n",
    "*Adaboost*: (Adaptive Boosting)\n",
    "- Each predictor pays more attention to instances wrongly predicted by its predecessor\n",
    "- Change weights of training samples\n",
    "- Each predictor has a coefficient $\\alpha$ that depends on that predictor's training error.\n",
    "- Learning rate $\\eta$: Between 0 and 1, used to shrink the coefficient $\\alpha$. Small value of $\\eta$ requires a larger number of estimators.\n",
    "- Classification: Majority voting, Regression: Weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.78\n",
      "Test set accuracy of bc: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver[['Liver_disease']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=2, min_samples_leaf=0.13, random_state=1)\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)\n",
    "\n",
    "ada.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "y_pred = ada.predict(X_test)\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Boosting*:\n",
    "- Does not tweak the weights of training samples\n",
    "- Each predictor is trained using its predecessors error as labels\n",
    "- Shrinkage $\\eta$: the prediction of each tree is shrunk by $\\eta$. Tradeoff with number of estimators like in Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 49.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "bikes = pd.read_csv('dc_bikes.csv')\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "y = bikes[['cnt']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "gb = GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=2)\n",
    "\n",
    "gb.fit(X_train, np.ravel(y_train))\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting must execute an exhaustive search, which might repeat CARTs with same split points/features.\n",
    "\n",
    "*Stochastic Gradient Boosting*:\n",
    "- Each tree trained on a random subset of rows in the sample, without replacement\n",
    "- Features are sampled without replacement when choosing split points\n",
    "- Adds more variance to the ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 47.454\n"
     ]
    }
   ],
   "source": [
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "                                 subsample=0.9,\n",
    "                                 max_features=0.75,\n",
    "                                 n_estimators=200,                                \n",
    "                                 random_state=2)\n",
    "sgbr.fit(X_train, np.ravel(y_train))\n",
    "y_pred = sgbr.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters\n",
    "\n",
    "Grid Search:\n",
    "- Set a metric for evaluating model performance\n",
    "- Manually search through a grid of discrete hyperparameter values\n",
    "- For each set of hyperparameters, get the model's CV score, pick the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.731\n",
      "Best hyerparameters:\n",
      " {'max_depth': 3, 'min_samples_leaf': 0.14}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver[['Liver_disease']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "params_dt = {'max_depth': [2,3,4],\n",
    "             'min_samples_leaf': [0.12,0.14,0.16,0.18]\n",
    "            }\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))\n",
    "\n",
    "print('Best hyerparameters:\\n', grid_dt.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameters:\n",
    "\n",
    "- CART hyperparameters\n",
    "- number of estimators\n",
    "- bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 54.282\n",
      "Best hyerparameters:\n",
      " {'max_features': 'auto', 'min_samples_leaf': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "X = bikes.drop('cnt', axis=1)\n",
    "y = bikes[['cnt']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "params_rf = {'n_estimators': [100,350,500],\n",
    "             'max_features': ['log2','auto','sqrt'],\n",
    "             'min_samples_leaf': [2,10,30]\n",
    "            }\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test))\n",
    "\n",
    "print('Best hyerparameters:\\n', grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
